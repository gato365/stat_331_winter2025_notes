---
title: "ETV - Task - Who is the real GOAT of all time in the NBA"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE)
```

Lets get up to date with our notes:

1.  `git checkout main` via notes project

2.  `git pull` request

3.  `git checkout your_branch_name`

4.  `git merge main`

## Description

MJ, LJ, and KB are the three most popular players in the NBA. They are all great players, but who is the real GOAT of all time in the NBA? In this task, you will analyze the data of these three players and find out who is the real GOAT of all time in the NBA. We have 1st 15 season for each player and we will analyze the data of these 15 seasons to find out who is the real GOAT of all time in the NBA while learning more ETV methods.

Background Information:

This dataset was originally extracted in 2019 as part of a research project I conducted. Since the data was sourced from an HTML webpage, significant cleaning was required to prepare it for analysis. In this class, we will explore various techniques for extracting and cleaning data from web pages, equipping you with practical skills for working with real-world datasets.

#### Learning Moment 1 - View Excel File

Lets Look at the excel file which contains the data of these three players.

**Q1.** How many tabs are in the excel sheet? What does each one represent?

5 sheets: KB, LJ, MJ, Variable Names, Divisions/Conferences

**Q2.** What do you suppose we should analyze to find out who is the real GOAT of all time in the NBA? List some variables and questions you may have based on what you see. There is no right answer here.

------------------------------------------------------------------------

**Here are my ideas on how to compare these players.**

**Sub Task 1:** Boxplot & Violin Plot with Mean

-   **Task Description**: Create a combined boxplot and violin plot comparing players against their points scored (`PTS`) during their first season, including mean markers and axis labels (make sure the axis titles are bolded). Interpret the distribution of points scored by each player and identify which player had the highest variability in points.

------------------------------------------------------------------------

**Sub Task 2:** Summarized Table for KB

-   **Task Description**: Generate a table summarizing `PTS` for Kobe Bryant (`KB`) during his first seven seasons. Compute the average, standard deviations points scored by KB, and the count of games he scored point, across these seasons or identify trends (e.g., season with the highest average). Arrange by highest variability in point to lowest so that we can understand his consistency.

------------------------------------------------------------------------

**Sub Task 3:** Confidence Intervals with Error Bars

-   **Task Description**: Create a plot displaying confidence intervals with error bars for Kobe Bryant's points across his first seven NBA seasons. Provide an explanation of what the confidence intervals represent and identify which player demonstrates the least overlap between their confidence intervals.

------------------------------------------------------------------------

**Sub Task 4:** Facet Grid for MP & PTS

-   **Task Description**: Use `facet_grid` to create visualizations comparing Minutes Played (`MP`) and Points (`PTS`) for different players during their first three seasons. Examine how the patterns of Minutes Played and Points Scored vary across season and player, and highlight any players who demonstrate standout performance.

------------------------------------------------------------------------

**Sub Task 5:** Barplot for Discretized Points

-   **Task Description**: Create a barplot showing the count of points (PTS), categorized into bins as follows: Low (PTS \< 20), Medium (20 ≤ PTS \< 30), and High (PTS ≥ 30). Use forcats to ensure the bins are ordered logically (Low, Medium, High). Compare the counts across player identities during the first season. Analyze which players had the most occurrences in each point range and interpret how the distribution varies among players.

------------------------------------------------------------------------

**Data Ethics:** The data used in this project was scraped from the Sports Reference website, a publicly accessible resource. This data is harmless in its intended use, focusing solely on historical player statistics for educational purposes in data analysis and visualization. However, data ethics should still be considered. For instance, while this data is not sensitive, ensuring proper attribution to the data source is essential to respect intellectual property.

Additionally, when working with data in general, it is important to avoid misrepresentation, maintain transparency about data collection methods, and consider privacy and consent, especially when analyzing personal or sensitive information. Ethical practices ensure that the data is used responsibly and for its intended purpose.

```{r}
## Location to install packages
install.packages("here")
install.packages("readxl")
install.packages("forcats")
install.packages("stringr")
```

#### Load Libraries (Empty)

```{r}
## Locations to load libraries
library(here)    # Data Extraction
library(readxl)  # Data Extraction
library(forcats) # Data Transformations
library(stringr) # Data Transformations
library(dplyr)   # Data Transformations
library(ggplot2) # Data Visualization
```

### Extraction

#### Learning Moment 2 - `here` and `read_xlsx` Packages

**Q3.** State the path to location to *nba_goats.xlsx* using the `here` function.

```{r}
## Code here
path_location_to_nba_file <- here("Data", "nba_goats.xlsx")
```

**Q4.** Run `path_location_to_nba_file` in the console. What do you see?

```{r}
nba_goats_df <- read_xlsx(path_location_to_nba_file)

# We only got Kobe's Sheet. It is stored within nba_goats_df.
```

------------------------------------------------------------------------

**Q5.** What number should be place in sheet to navigate to LeBron's Sheet?

```{r}
lj_df <- read_xlsx(path_location_to_nba_file, sheet = 2) ## Provide the number for LJ
```

*Note 1:* the name of the data frame. I use `_df` to signify that the object is a data frame

**Q6.** If we wanted to get Michael Jordan's table using his name instead, how do we do that?

```{r}
mj_df <- read_xlsx(path_location_to_nba_file, sheet = "MJ") ## Provide the name for MJ
```

**Q7.** Get Kobe Bryant and the variable names in anyway you would like.

```{r}
kb_df <- read_xlsx(path_location_to_nba_file, sheet = "KB") ## Provide the name for MJ
```

**Q8.** Lets look at the data frame of Variables Meanings to get a better sense of the information. What does `GmSc` denote?

```{r}
variables_df <- read_xlsx(path_location_to_nba_file, sheet = "variable_names")

View(variables_df)

#Game Score (Hollinger productivity metric)
```

------------------------------------------------------------------------

### Transformation

#### Learning Moment 3 - `bind_rows` & `bind_cols` (A digression)

From HW 1 you learned to create data frames.

**Step 1: Create Data Frames**

**Q9.** Below are three data frames that will be used in this Learning Moment. Fill in the appropriate functions to create 3 data frames from vectors.

```{r}
# Data frame 1: Information about Group A
#ex_1_df_a <- data.frame(
#  id = c(1, 2, 3),
#  name = c("Alice", "Bob", "Charlie"),
#  score = c(85, 90, 78)
#)

# Data frame 2: Information about Group B
#ex_1_df_b <- data.frame(
#  id = c(4, 5, 6),
#  name = c("David", "Ella", "Fiona"),
#  score = c(88, 92, 81)
#)

# Data frame 3: Additional details for Group A
#ex_1_df_details <- data.frame(
#  age = c(25, 30, 35),
#  location = c("NY", "CA", "TX")
#)

# Print the data frames to understand their structure
#print(ex_1_df_a)
#print(ex_1_df_b)
#print(ex_1_df_details)
```

Sometime it is easier to analyze data if multiple data frames are merge in some way. Below we will learn two ways of doing this.

------------------------------------------------------------------------

**Step 2: Combine (or just bind) the Data Frames**

Now that we have created the data frames, let’s bring them together for analysis using `bind_rows()` and `bind_cols()`.

##### **Using `bind_rows()`**

```{r}
# Combine Group A and Group B
ex_1_combined_rows <- bind_rows(ex_1_df_a, ex_1_df_b)

# Print the combined data frame
print(ex_1_combined_rows)
```

**Q10.** What is the purpose of the `bind_rows` function?

Combine data frames by stacking them vertically (on top of each other).\
It is useful when multiple data frames have the same columns.

**Q11.** What happens if the column names do not match when using `bind_rows()`? For example change `score` to `score_ex` in `ex_1_df_b`.

It creates a new column and creates empty cells for where they don't have a value.

------------------------------------------------------------------------

##### **Using `bind_cols()`**

```{r}
# Add additional details to Group A
ex_1_combined_cols <- bind_cols(ex_1_df_a, ex_1_df_details)

# Print the combined data frame
print(ex_1_combined_cols)
```

**Q12.** What is the purpose of the `bind_cols` function?

Combine data frames by stacking them horizontally (side by side of each other).\
It is useful when multiple data frames have the same number of rows in each data frame?

**Q13.** What happens if the number of rows do not match when using `bind_cols()`?

You get a error. You cannot bind two different data frames with different size rows.

**Q14.** What could be dangerous with `bind_cols` when working with real data?

You might mismatch your binding.

**End of the digression**

**Q15.** Which function (`bind_rows` or `bind_cols`) should we use to bind the data frames of the players (MJ, KB, LJ) into 1 data frame?

**Q16.** Go ahead and bind the data frames together.

```{r}
nba_goats_df <-bind_rows(mj_df, kb_df, lj_df)
```

I intentionally over wrote `nba_goats_df`

```{r}
glimpse(nba_goats_df)
```

------------------------------------------------------------------------

#### Learning Moment 4 - Characters and Factors

**Character/String**: A data type used to store text or strings of characters. It’s ideal for unique identifiers, descriptive labels, or free text.

**Character/String:**

-   **If the values are unique or near-unique** (e.g., names, IDs, or free text).
-   **When the order or grouping is irrelevant** (e.g., descriptions or unstructured data).
-   **If you’re performing text manipulation** (e.g., extracting substrings, concatenating values).

**Factor**: A data type used for categorical data with a fixed set of possible values (levels). It’s useful for grouping, ordering, and efficient memory usage in analysis or visualization.

**Factor:**

-   **If the variable represents a category** (e.g., gender, game location, or outcomes like "Win" and "Loss").
-   **When you need levels to have a specific order** (e.g., "Small", "Medium", "Large").
-   **To save memory when the variable has repeated values** in large datasets.
-   **When creating visualizations** where categorical groupings are important (e.g., bar plots grouped by category).
-   **When running models or analyses that rely on categorical data** (e.g., logistic regression, ANOVA).

### **Quick Guideline**:

-   **Character/String:** Unique identifiers, descriptive text, or unstructured data.
-   **Factor:** Grouping, categorization, or ordered levels used for analysis or visualization.

**Q17.** When glancing at the data, which variables should be converted into factors to enhance their usefulness for potential analysis?

**Q18.** Let's do 1 variable that should be considered a factor, convert `Name` to a factor, but name it `Name_Factor`.

```{r}
## Code here
mod_1_nba_goats_df <- nba_goats_df %>%
  mutate(Name_Factor = as.factor(Name))
```

**What are the visible benefits?**

**Version 1:** Linear Model with Default Baseline (`KB`)

By default, R uses the first level of the factor (alphabetically) as the baseline.

```{r}
# Perform Linear Model with default baseline
lm_result_default <- lm(PTS ~ Name_Factor, data = mod_1_nba_goats_df)

# View the summary
summary(lm_result_default)
```

**Version 2:** Set `MJ` as the Baseline

In order to do this we have to install and load forcats, be sure to install and load this package and place it in the appropriate location in the code. To change the baseline, reorder the levels of the `Name` factor so that `MJ` is the first level.

```{r}
## Code here
mod_2_nba_goats_df <- nba_goats_df %>%
  mutate(Name_Factor = as_factor(Name)) %>%
  mutate(Name_Factor = fct_relevel(Name_Factor, c("MJ", "KB", "LJ")))
```

Let's see what this looks like:

```{r}
# Perform Linear with MJ as the baseline
lm_result_mj_baseline <- lm(PTS ~ Name_Factor, data = mod_2_nba_goats_df)

# View the summary
summary(lm_result_mj_baseline)
```

------------------------------------------------------------------------

#### Learning Moment 5 - Manipulating Strings & `case_when` in R

Install the `stringr` package in the right location and load the library in the right section of the code.

**Objective:** Rename the `Game_Outcome` values from `"W"` and `"L"` to `"Win"` and `"Loss"`.

```{r}
# Rename Game_Outcome using str_replace (using case_when)
mod_3_nba_goats_df <- mod_2_nba_goats_df %>%
  mutate(
     Game_Outcome_Renamed = case_when(
       str_detect(Game_Outcome,"W") ~ "Win",
       str_detect(Game_Outcome,"L") ~ "Loss"
  )
)
```

**Q19.** What is the purpose of `str_detect()`?

Given a variable (or column) it looks for a specific sub string (within the character column).

**Q20.** What is the purpose of `case_when()`?

To make new categorical variables based on a condition.

**Q21.** What other function could we have used instead of `case_when`? Hint: Think of HW 1.

We would've used an 'if-else'.

```{r}
# Another way would be to use if_else
mod_4_nba_goats_df <- mod_2_nba_goats_df %>%
  mutate(
     Game_Outcome_Renamed = if_else(
       str_detect(Game_Outcome,"W"), "Win", "Loss"
  )
)
```

------------------------------------------------------------------------

Lets use `case_when` with quantitative data Categorize Points Scored (`PTS`) for Michael Jordan (`MJ`)

**Objective:** Create a new variable that categorizes `PTS` into three levels:

-   `"Low"` for points scored less than 20.

-   `"Medium"` for points between 20 and 30 (inclusive).

-   `"High"` for points greater than 30.

```{r}
# # Categorize PTS for MJ
 mod_5_nba_goats_df <- mod_3_nba_goats_df %>%
   filter(Name == "MJ") %>%  # Focus on Michael Jordan's data
   mutate(
     PTS_Category = case_when(
       PTS < 20 ~ "Low",
       PTS >= 20 & PTS <= 30 ~ "Medium",
       PTS > 30 ~ "High"
     )
   )

```

```{r}
# View categorized data
head(select(mod_5_nba_goats_df, Name, PTS, PTS_Category))
```

### Visualization

#### **Sub Task 1:** Boxplot & Violin Plot with Mean

-   **Task Description**: Create a combined boxplot and violin plot comparing players against their points scored (`PTS`) during their first season, including mean markers and axis labels (make sure the axis titles are bolded). Interpret the distribution of points scored by each player and identify which player had the highest variability in points.

```{r}
## Student Version
nba_goats_df %>%
  filter(Season == "season_1") %>%
  select(Name, PTS) %>%
  ggplot(aes(x = Name, y = PTS)) +
  geom_violin() + 
  geom_boxplot(fill = "lightblue", color = "blue") +
  stat_summary(
    fun = mean, geom = "point", color = "red"
  ) + 
  labs(title = "PTS distribution by player during 1st season",
       x = "Player Name",
       y = "Points Per Game") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), axis.title = element_text(face = "bold"))
```

**Q22.** What do you notice? Rank them according to their means. Why did Kobe Bryant not perform well during his 1st year in the NBA?

MJ had the highest, followed by LJ, with KB as last.

KB had a slow start because he had just gotten out of high school and he was not a starter.

*Let's investigate Kobe a tad bit more.*

#### **Sub Task 2:** Summarized Table for KB

-   **Task Description**: Generate a table summarizing `PTS` for Kobe Bryant (`KB`) during his first 7 seasons. Compute the average, standard deviations points scored by KB across these seasons or identify trends (e.g., season with the highest average). Arrange by highest variability in point to lowest so that we can understand his consistency.

```{r}
## Student Version
kb_summary_stats_df <- nba_goats_df %>%
  filter(str_detect(Name, "KB"), Season %in% str_c("season_", 1:7)) %>%
  group_by(Season) %>%
  summarise(`Mean KB PTS` = mean(PTS, na.rm = TRUE), 
            `SD KB PTS` = sd(PTS, na.rm = TRUE),
            `Number of Games` = n()) %>%
  arrange(desc(`SD KB PTS`))
```

#### **Sub Task 3:** Confidence Intervals with Error Bars

-   **Task Description**: Create a plot displaying confidence intervals with error bars for Kobe Bryant's points across his first seven NBA seasons. Provide an explanation of what the confidence intervals represent and identify which season demonstrates the least overlap between his confidence intervals.

We have to break this up into two steps:

*Step 1:* Create Lower and Upper Bounds

**Q23.** What do we need to calculate the lower and upper bounds of a confidence interval?

```{r}
## Student Version
ci_kb_df <- kb_summary_stats_df %>%
  mutate(se = `SD KB PTS` / sqrt(`Number of Games`),
         lower_bound = `Mean KB PTS` - 1.96*se,
         upper_bound = `Mean KB PTS` + 1.96*se)
```

*Step 2:* Create the Visualization

```{r}
## Student Version
ci_kb_df %>%
  select(lower_bound, upper_bound, `Mean KB PTS`, Season) %>%
  ggplot(aes(x = Season, y = `Mean KB PTS`)) +
  geom_point() + 
  geom_errorbar(aes(ymin = lower_bound, ymax = upper_bound))
```

#### **Sub Task 4:** Facet Grid for MP & PTS

-   **Task Description**: Use `facet_grid` to create visualizations comparing Minutes Played (`MP`) and Points (`PTS`) for different players during their first three seasons. Examine how the patterns of Minutes Played and Points Scored vary across season and player, and highlight any players who demonstrate standout performance.

```{r}
## Student Version
```

#### **Sub Task 5:** Barplot for Discretized Points

-   **Task Description**: Create a barplot showing the count of points (PTS), categorized into bins as follows: Low (PTS \< 20), Medium (20 ≤ PTS \< 30), and High (PTS ≥ 30). Use forcats to ensure the bins are ordered logically (Low, Medium, High). Compare the counts across player identities during the first season. Analyze which players had the most occurrences in each point range and interpret how the distribution varies among players.

```{r}
## Student Version
```

## Recap

Q1. What new libraries did you learn?

Q2. What functions within each library did you learn?

Q3. Ho did you use each function? Specify whether what part of ETV was the function used for.
